# Need to install Beautiful Soup (Anaconda don't give Beautiful Soup (By default))

# conda install beautifulsoup4 lxml

# beautifulsoup -> package that help us to webscraping
# lxml ->  help us to parse html and extract the data from it 


from bs4 import BeautifulSoup


with open("htmls/page1.html") as f:    # By default read mode
    content = f.read()


soup = BeautifulSoup(content, "html.parser")


# Extract all h3

h3s = soup.find_all("h3")


h3s


# Extract first h3 ancher tag title of first three

for h3 in h3s:
    print(h3.find("a")["title"])
    if(h3.find("a")["title"] == "Sharp Objects"):
        break


# Extract price and many more info from article tag in the form of list

articles = soup.select("article.product_pod")


items = []

for article in articles:
    title = article.find("h3").find("a")["title"]
    price = article.select_one("p.price_color").text.split("Â£")[1]
    rating_element = article.select_one("p.star-rating")
    
    classes = rating_element['class']
    # print(classes)
    
    rating = rating_element['class'][1]
    # print(price)
    # print(rating)
    items.append([title, price, rating])


items



import pandas as pd 


df = pd.DataFrame(items, columns=["Book Title","Price","Rating"])


df


df.to_csv("data.csv",index=False)
